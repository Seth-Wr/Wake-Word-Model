{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5154428-4a08-4ef8-ac3e-ea17718bde82",
   "metadata": {},
   "source": [
    "This first function adds random background noise from the musan data set in distored random intervals into the positive class and i changed directories to run on my negative data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4876eb17-5fc9-477a-9550-617d5a459109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "TARGET_SAMPLE_RATE = 16000\n",
    "MAX_SECONDS = 15\n",
    "MAX_SAMPLES = TARGET_SAMPLE_RATE * MAX_SECONDS\n",
    "\n",
    "# Random noise dataset\n",
    "def load_musan_noises(musan_dir):\n",
    "    noise_files = []\n",
    "    for subdir in ['noise', 'music', 'speech']:\n",
    "        subpath = os.path.join(musan_dir, subdir)\n",
    "        if os.path.exists(subpath):\n",
    "            for root, _, files in os.walk(subpath):\n",
    "                for file in files:\n",
    "                    if file.endswith('.wav'):\n",
    "                        noise_files.append(os.path.join(root, file))\n",
    "    return noise_files\n",
    "\n",
    "def add_background_noise(signal, sample_rate, noise_files, snr_db_range=(0, 15)):\n",
    "    if not noise_files:\n",
    "        return signal\n",
    "    \n",
    "    noise_path = random.choice(noise_files)\n",
    "    noise, noise_sr = torchaudio.load(noise_path)\n",
    "    \n",
    "    if noise_sr != sample_rate:\n",
    "        noise = torchaudio.transforms.Resample(noise_sr, sample_rate)(noise)\n",
    "    \n",
    "    sig_len = signal.shape[1]\n",
    "    noise_len = noise.shape[1]\n",
    "\n",
    "    if noise_len > sig_len:\n",
    "        start = random.randint(0, noise_len - sig_len)\n",
    "        noise = noise[:, start:start + sig_len]\n",
    "    elif noise_len < sig_len:\n",
    "        pad_left = random.randint(0, sig_len - noise_len)\n",
    "        pad_right = sig_len - noise_len - pad_left\n",
    "        noise = torch.nn.functional.pad(noise, (pad_left, pad_right))\n",
    "    \n",
    "    # Compute SNR\n",
    "    snr_db = random.uniform(*snr_db_range)\n",
    "    signal_power = torch.mean(signal ** 2)\n",
    "    noise_power = torch.mean(noise ** 2)\n",
    "    factor = torch.sqrt(signal_power / (noise_power * 10 ** (snr_db / 10)))\n",
    "    noise.mul_(factor)  # in-place\n",
    "    signal.add_(noise)  # in-place\n",
    "    signal.div_(torch.max(torch.abs(signal)))  # normalize in-place\n",
    "    return signal\n",
    "\n",
    "def time_stretch(signal, rate):\n",
    "    signal_np = signal.numpy().flatten()\n",
    "    stretched = librosa.effects.time_stretch(signal_np, rate=rate)\n",
    "    return torch.tensor(stretched, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "def apply_manual_gain(signal, gain_db):\n",
    "    gain_linear = 10 ** (gain_db / 20)\n",
    "    signal.mul_(gain_linear)  # in-place\n",
    "    return signal\n",
    "\n",
    "def augment_audio(audio_path, musan_noises, output_dir):\n",
    "    signal, orig_sr = torchaudio.load(audio_path)\n",
    "    \n",
    "    # Resample if needed\n",
    "    if orig_sr != TARGET_SAMPLE_RATE:\n",
    "        signal = torchaudio.transforms.Resample(orig_sr, TARGET_SAMPLE_RATE)(signal)\n",
    "    \n",
    "    # Trim long audio\n",
    "    if signal.shape[1] > MAX_SAMPLES:\n",
    "        signal = signal[:, :MAX_SAMPLES]\n",
    "\n",
    "    # Augmentations\n",
    "    if random.random() < 0.5:\n",
    "        signal = add_background_noise(signal, TARGET_SAMPLE_RATE, musan_noises)\n",
    "\n",
    "    if random.random() < 0.5:\n",
    "        pitch_shift = random.uniform(-4, 4)\n",
    "        signal = torchaudio.functional.pitch_shift(signal, TARGET_SAMPLE_RATE, n_steps=pitch_shift)\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        rate = random.uniform(0.8, 1.2)\n",
    "        signal = time_stretch(signal, rate)\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        gain_db = random.uniform(-6, 6)\n",
    "        signal = apply_manual_gain(signal, gain_db)\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        noise = torch.normal(0, random.uniform(0.001, 0.015), signal.shape)\n",
    "        signal.add_(noise)\n",
    "        signal.div_(torch.max(torch.abs(signal)))  # normalize\n",
    "\n",
    "    # Save augmented file\n",
    "    base_name = os.path.basename(audio_path)\n",
    "    output_path = os.path.join(output_dir, f\"aug_{base_name}\")\n",
    "    sf.write(output_path, signal.numpy().flatten(), TARGET_SAMPLE_RATE)\n",
    "\n",
    "    # Free memory\n",
    "    del signal\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "def main(input_dir, musan_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    musan_noises = load_musan_noises(musan_dir)\n",
    "    if not musan_noises:\n",
    "        print(\"Warning: No MUSAN noise files found. Skipping background noise augmentation.\")\n",
    "    \n",
    "    # Recursively gather all WAV files\n",
    "    wav_files = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                wav_files.append(os.path.join(root, file))\n",
    "    \n",
    "    print(f\"Found {len(wav_files)} WAV files to augment.\")\n",
    "\n",
    "    for idx, audio_path in enumerate(wav_files, 1):\n",
    "        try:\n",
    "            augmented_path = augment_audio(audio_path, musan_noises, output_dir)\n",
    "            print(f\"[{idx}/{len(wav_files)}] Augmented and saved: {augmented_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{idx}/{len(wav_files)}] Error processing {audio_path}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    musan_dir = \"/Users/sethwright/Downloads/musan\"\n",
    "    input_dir = \"/Users/sethwright/Documents/audio-model/data/sheila\"\n",
    "    output_dir = \"/Users/sethwright/Documents/audio-model/data/Training_POS\"\n",
    "    main(input_dir, musan_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e05ae7-e725-4887-894a-6c3b3da9f5b8",
   "metadata": {},
   "source": [
    "This function is to split a long background noise mp3 i found into wav and into 1 second intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa964a-63fc-4a25-9070-c1c4463019b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "# Split background noise data set from long mp3 for negative class\n",
    "def convert_and_split_mp3s(\n",
    "    input_dir = \"/Users/sethwright/Downloads/archive/_background_noise_\"    ,\n",
    "    output_dir = \"/Users/sethwright/Documents/audio-model/data/background_data\" ,\n",
    "    sample_rate=16000,\n",
    "    clip_duration=1,\n",
    "    overlap_duration=0.25\n",
    "):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Convert durations to samples\n",
    "    clip_samples = int(sample_rate * clip_duration)\n",
    "    overlap_samples = int(sample_rate * overlap_duration)\n",
    "    step_size = clip_samples - overlap_samples  # how far we move forward each chunk\n",
    "\n",
    "    # Walk through all files in the input directory\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for fname in files:\n",
    "            if not fname.lower().endswith(\".wav\"):\n",
    "                continue\n",
    "\n",
    "            in_path = os.path.join(root, fname)\n",
    "            base_name = os.path.splitext(fname)[0]\n",
    "\n",
    "            try:\n",
    "                # -------------------------------------------------------\n",
    "                # 1ï¸âƒ£ Load audio (mono, 16 kHz)\n",
    "                # -------------------------------------------------------\n",
    "                y, sr = librosa.load(in_path, sr=sample_rate, mono=True)\n",
    "                total_samples = len(y)\n",
    "\n",
    "                # -------------------------------------------------------\n",
    "                # 2ï¸âƒ£ Compute how many clips will be produced\n",
    "                # -------------------------------------------------------\n",
    "                num_chunks = int(np.ceil((total_samples - overlap_samples) / step_size))\n",
    "\n",
    "                # -------------------------------------------------------\n",
    "                # 3ï¸âƒ£ Split into overlapping chunks\n",
    "                # -------------------------------------------------------\n",
    "                for i in range(num_chunks):\n",
    "                    start = i * step_size\n",
    "                    end = start + clip_samples\n",
    "                    clip = y[start:end]\n",
    "\n",
    "                    # Pad the last clip with zeros if too short\n",
    "                    if len(clip) < clip_samples:\n",
    "                        clip = np.pad(clip, (0, clip_samples - len(clip)))\n",
    "\n",
    "                    # Output filename: base_chunk001.wav\n",
    "                    out_name = f\"{base_name}_chunk{i+1:03d}.wav\"\n",
    "                    out_path = os.path.join(output_dir, out_name)\n",
    "\n",
    "                    # ---------------------------------------------------\n",
    "                    # 4ï¸âƒ£ Save WAV file (float32 â†’ 16-bit PCM)\n",
    "                    # ---------------------------------------------------\n",
    "                    sf.write(out_path, clip, sample_rate, subtype='PCM_16')\n",
    "\n",
    "                print(f\"âœ… {fname}: {num_chunks} clips created\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error processing {fname}: {e}\")\n",
    "\n",
    "    print(\"\\nðŸŽ‰ All files converted and split successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbcec47-25e0-4040-96fd-69da56940286",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_and_split_mp3s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25372c-8d1e-4793-9c07-766b6da9dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import contextlib\n",
    "# Find average Legnth to use for your model specs \n",
    "# Path to your directory containing audio files\n",
    "audio_dir = \"/Users/sethwright/Documents/audio-model/data/sheila\"\n",
    "\n",
    "durations = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith(\".wav\"):  # Change this if your files have a different extension\n",
    "        file_path = os.path.join(audio_dir, filename)\n",
    "        with contextlib.closing(wave.open(file_path, 'r')) as f:\n",
    "            frames = f.getnframes()\n",
    "            rate = f.getframerate()\n",
    "            duration = frames / float(rate)\n",
    "            durations.append(duration)\n",
    "\n",
    "if durations:\n",
    "    smallest = min(durations)\n",
    "    largest = max(durations)\n",
    "    average = sum(durations) / len(durations)\n",
    "    print(f\"Smallest duration: {smallest:.2f} seconds\")\n",
    "    print(f\"Largest duration: {largest:.2f} seconds\")\n",
    "    print(f\"Average duration: {average:.2f} seconds\")\n",
    "else:\n",
    "    print(\"No audio files found in the directory.\")\n",
    "\n",
    "# Delete files too far out of range\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith(\".wav\"):  # only process WAV files\n",
    "        file_path = os.path.join(audio_dir, filename)\n",
    "        with contextlib.closing(wave.open(file_path, 'r')) as f:\n",
    "            frames = f.getnframes()\n",
    "            rate = f.getframerate()\n",
    "            duration = frames / float(rate)\n",
    "            if duration < .6:\n",
    "                print(f\"Deleting {filename} (duration: {duration:.2f}s)\")\n",
    "                os.remove(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-kernel",
   "language": "python",
   "name": "audio-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
